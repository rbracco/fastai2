{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.data.all import *\n",
    "from fastai2.audio.core import *\n",
    "from fastai2.audio.augment import *\n",
    "from fastai2.callback.all import *\n",
    "from fastai2.vision.all import *\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Training a Voice Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p10speakers = Config()['data_path'] / 'ST-AEDS-20180100_1-OS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jupyter/.fastai/data/250_speakers/250-speakers')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Warning this dataset is ~8GB\n",
    "p250speakers = Config()['data_path'] / '250_speakers'\n",
    "untar_data(URLs.SPEAKERS250, fname=str(p250speakers)+'.tar', dest=p250speakers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = AudioGetter(\"\", recurse=True, folders=None)\n",
    "files_10  = x(p10speakers)\n",
    "files_250 = x(p250speakers)\n",
    "#original_aud = AudioItem.create(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datablock and Basic End to End Training on 10 Speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AudioBlock(cls=AudioItem): return TransformBlock(type_tfms=cls.create, batch_tfms=IntToFloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auds = DataBlock(blocks=(AudioBlock, CategoryBlock),  \n",
    "                 get_items=get_audio_files, \n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=lambda x: str(x).split('/')[-1][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [y for _,y in auds.datasource(p10speakers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify categories are being correctly assigned\n",
    "test_eq(min(cats).item(), 0)\n",
    "test_eq(max(cats).item(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crop 2s from the signal and turn it to a MelSpectrogram with no augmentation\n",
    "cfg_voice = AudioConfig.Voice()\n",
    "a2s = AudioToSpec.from_cfg(cfg_voice)\n",
    "crop_2000ms = CropSignal(2000)\n",
    "tfms = [crop_2000ms, a2s]\n",
    "dbunch = auds.databunch(p10speakers, item_tfms=tfms, bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-block alert-warning\"><strong>Broken:</strong><br>Show batch is broken as it appears to just be grabbing the data from the sg, and not the sg object itself, but calls the sg's show method which relies on nchannels, which is an object of AudioSpectrogram (part of sg settings but we overrode getattr to make it work like an attribute). This means that, for the moment, the items cant show themselves for the batch, but training still works </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dbunch_cropspec.show_batch(max_n=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 128, 251])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbunch.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit to Kevin Bird and Hiromi Suenaga for these two lines to adjust a CNN model to take 1 channel input\n",
    "def alter_learner(learn, channels=1):\n",
    "    learn.model[0][0].in_channels=channels\n",
    "    learn.model[0][0].weight = torch.nn.parameter.Parameter(learn.model[0][0].weight[:,1,:,:].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dbunch, \n",
    "                xresnet18(),\n",
    "                torch.nn.CrossEntropyLoss(), \n",
    "                metrics=[accuracy])\n",
    "nchannels = dbunch.one_batch()[0].shape[1]\n",
    "alter_learner(learn, nchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='10', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      60.00% [6/10 18:21<12:14]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.952065</td>\n",
       "      <td>5.001875</td>\n",
       "      <td>0.217448</td>\n",
       "      <td>03:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.820696</td>\n",
       "      <td>3.831397</td>\n",
       "      <td>0.338542</td>\n",
       "      <td>03:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.450232</td>\n",
       "      <td>9.597190</td>\n",
       "      <td>0.240885</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.253995</td>\n",
       "      <td>1.266126</td>\n",
       "      <td>0.743490</td>\n",
       "      <td>03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155395</td>\n",
       "      <td>0.363358</td>\n",
       "      <td>0.877604</td>\n",
       "      <td>03:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>1.829377</td>\n",
       "      <td>0.665365</td>\n",
       "      <td>03:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='48', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [36/48 02:05<00:41 0.0712]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#epochs are a bit longer due to the chosen melspectrogram settings\n",
    "learn.fit_one_cycle(10, lr_max=slice(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on 250 Speakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(files_250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(random.choice(files_250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_250speakers_label = lambda x: str(x).split('/')[-3][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    f = random.choice(files_250)\n",
    "    print(\"File:\",f )\n",
    "    print(\"Label:\", get_250speakers_label(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auds = DataBlock(blocks=(AudioBlock, CategoryBlock),  \n",
    "                 get_items=get_audio_files, \n",
    "                 splitter=RandomSplitter(),\n",
    "                 get_y=get_250speakers_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch250 = auds.databunch(p250speakers, item_tfms=tfms, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress import progress_bar as pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [y for _,y in pb(auds.datasource(p250speakers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify categories are being correctly assigned for 250 speakers\n",
    "test_eq(min(cats).item(), 0)\n",
    "test_eq(max(cats).item(), 249)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torchaudio default MelSpectrogram to get a baseline\n",
    "a2s = AudioToSpec()\n",
    "crop_4000ms = CropSignal(4000)\n",
    "tfms = [crop_4000ms, a2s]\n",
    "dbunch = auds.databunch(p250speakers, item_tfms=tfms, bs=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dbunch, \n",
    "                xresnet18(),\n",
    "                torch.nn.CrossEntropyLoss(), \n",
    "                metrics=[accuracy])\n",
    "nchannels = dbunch.one_batch()[0].shape[1]\n",
    "alter_learner(learn, nchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, lr_max=slice(2e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, lr_max=slice(1e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize our AudioToSpec Function using a config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voice_cfg = AudioConfig.Voice()\n",
    "a2s = AudioToSpec.from_cfg(voice_cfg)\n",
    "tfms = [crop_4000ms, a2s]\n",
    "# tfms = Pipeline([CropSignal(4000),  a2s, MaskFreq(size=12), MaskTime(size=15), SGRoll()], as_item=True)\n",
    "dbunch = auds.databunch(p250speakers, item_tfms=tfms, bs=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dbunch, \n",
    "                xresnet18(),\n",
    "                torch.nn.CrossEntropyLoss(), \n",
    "                metrics=[accuracy])\n",
    "nchannels = dbunch.one_batch()[0].shape[1]\n",
    "alter_learner(learn, nchannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better results even without fine tuning, but much slower. We need to move a2s to the GPU and \n",
    "# then add data augmentation!\n",
    "learn.fit_one_cycle(5, lr_max=slice(2e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an MFCC with Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only grab 1500ms of the clip, voice identity can be done with shorter sections and it will speed it up\n",
    "# this is really slow for mfcc, even for 45k files, need to figure out what's going on here. Also the results\n",
    "# shouldn't be this much worse than melspectrogram\n",
    "a2mfcc = AudioToMFCC(n_mffc=20, melkwargs={\"n_fft\":2048, \"hop_length\":256, \"n_mels\":128})\n",
    "tfms = [CropSignal(1500), a2mfcc, Delta()]\n",
    "# tfms = Pipeline([CropSignal(4000),  a2s, MaskFreq(size=12), MaskTime(size=15), SGRoll()], as_item=True)\n",
    "dbunch = auds.databunch(p250speakers, item_tfms=tfms, bs=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_mfcc isn't getting passed down? \n",
    "dbunch.one_batch()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dbunch, \n",
    "                xresnet18(),\n",
    "                torch.nn.CrossEntropyLoss(), \n",
    "                metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, lr_max=slice(2e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(7, lr_max=slice(3e-3, 4e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-block alert-info'><strong>From Here:</strong><br>\n",
    "    1. Get transforms on the GPU <br>\n",
    "    2. Once it's faster test signal and spectrogram augments for speed/efficacy<br>\n",
    "    3. Fine-tune and see how high we can push results on 250 speakers\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
