{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct TestModel: Layer {\n",
    "    public var layer1: Dense<Float>\n",
    "    public var layer2: Dense<Float>\n",
    "    \n",
    "    public init(nIn: Int, nHid: Int, nOut: Int){\n",
    "        layer1 = Dense(inputSize: nIn, outputSize: nHid, activation: relu)\n",
    "        layer2 = Dense(inputSize: nHid, outputSize: nOut)\n",
    "    }\n",
    "    \n",
    "    @differentiable\n",
    "    public func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: layer1, layer2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Initialize a tensor to use the GPU and load the libraries needed\n",
    "let y = Tensor<Int32>(zeros: [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "427Mb used PyTorch takes 787Mb so S4TF is better there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = TestModel(nIn: 4096, nHid: 2048, nOut: 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "555Mb so new usage of 128Mb. Model uses (4096x2048 + 2048 + 2048x512 + 512) x 4 bytes = 36Mb so we're using 4 times more memory than theoretically necessary.\n",
    "\n",
    "PyTorch uses 52Mb at this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in 0..<100 {\n",
    "    let x = Tensor<Float>(randomNormal: [32, 4096])\n",
    "    let y = Tensor<Int32>(zeros: [32])\n",
    "    let out = model(x)\n",
    "    let loss = softmaxCrossEntropy(logits: out, labels: y)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "659Mb used so new usage of 104Mb. There might be some library loading in those, hard to test what exactly is our usage. Those 104Mb don't change with the size of the model (unless we go to much bigger sizes) but the activations tensors aren't very heavy compared to the model weights.\n",
    "\n",
    "PyTorch new usage is 64Mb so 40Mb less, but it might be because it alrady loaded some of those libraries in the big init."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in 0..<100 {\n",
    "    let x = Tensor<Float>(randomNormal: [32, 4096])\n",
    "    let y = Tensor<Int32>(zeros: [32])\n",
    "    let out = model(x)\n",
    "    let (loss, grads) = model.valueWithGradient {\n",
    "        softmaxCrossEntropy(logits: $0(x), labels: y)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "787Mb used so new usage of 128Mb (almost 4 times what's necessary for gradients, normally 36Mb)\n",
    "\n",
    "PyTorch uses 64Mb more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var opt = Adam(for: model)\n",
    "for _ in 0..<100 {\n",
    "    let x = Tensor<Float>(randomNormal: [32, 4096])\n",
    "    let y = Tensor<Int32>(zeros: [32])\n",
    "    let out = model(x)\n",
    "    let (loss, grads) = model.valueWithGradient {\n",
    "        softmaxCrossEntropy(logits: $0(x), labels: y)\n",
    "    }\n",
    "    opt.update(&model, along: grads)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1043MB so new usage of 256Mb (again, almost 4 times what's necessary since we add two new saved tensors, averages and square averages for the model, so normally 2x36Mb).\n",
    "\n",
    "PyTorch uses 96Mb more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
